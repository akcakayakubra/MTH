# -*- coding: utf-8 -*-
"""MTH410.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p__4rwvl60XweDRIZgaxj8Tn5ebE9c-_
"""

from google.colab import drive
drive.mount ('/content/drive')

import os
os.chdir("drive/My Drive/csv files for mth410")

import pandas as pd

df = pd.read_csv("03-02-2018.csv")

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import csv

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, auc, confusion_matrix
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from itertools import cycle

df.head(10)

"""Data Preprocessing"""

df.shape

#Get unique values in Label column
df.loc[:,'Label'].unique()

#Find the columns containing missing value

missing_values = df.isna().sum()
columns_with_missing_values = missing_values[missing_values > 0].index

print("Columns with missing values:")
for column in columns_with_missing_values:
    print(column)

#Plot the columns containing null values
zero_counts = (df == 0).sum()

plt.figure(figsize=(4, 3))
plt.bar(['Not Null=0', 'Null=1'], [zero_counts[zero_counts > 0].count(), zero_counts[zero_counts == 0].count()])
plt.xlabel('Feature')
plt.ylabel('The number of features')
plt.title('Columns with Null Values')
plt.show()

#Plot missing values in each column
def plotMissingValues(dataframe):
  missing_values = dataframe.isnull().sum()
  fig = plt.figure(figsize=(16,5))
  missing_values.plot(kind='bar')
  plt.xlabel("Features")
  plt.ylabel("Missing values")
  plt.title("Total number of Missing values in each feature")
  plt.show()

plotMissingValues(df)

#Rows wilth null values are removed

data_f = df.dropna()

#Plot data after removing the null values
plt.figure(1,figsize=(10,4))
plt.hist(data_f.isna().sum())

plt.title('Data after removing the Null Values')
plt.xlabel('The number of null values')
plt.ylabel('Number of columns')
plt.show()

(data_f.dtypes == 'object')

#Categorical values in the 'Label' column are converted to numerical values
data_f['Label'] = data_f['Label'].map({'Benign' : 0, 'Bot':1})

#Find the number of Benign class and Bot class
def count_classes_as_dict(dataframe, column_name):
    class_counts = dataframe[column_name].value_counts().to_dict()
    return class_counts
class_counts_dict = count_classes_as_dict(data_f, 'Label')
print(class_counts_dict)

#Plot the number of classes
plt.hist(data_f['Label'], bins = [0, 0.3, 0.7, 1], edgecolor='black')
plt.xticks([0,1], labels = ['Benign=0', 'Bot=1'])
plt.xlabel("Classes")
plt.ylabel("Count")
plt.show()

"""Data Exploring"""

df.describe()

"""Data Splitting into Train and Test"""

pd.set_option('use_inf_as_na', True)

n_values=data_f.isnull().sum()
print(n_values)

data_n = data_f.drop('Timestamp', axis=1)

X = data_n.drop('Label', axis=1)
y = data_n['Label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.replace([np.inf, -np.inf], np.nan, inplace=True)
X_test.replace([np.inf, -np.inf], np.nan, inplace=True)

X_train.dropna(inplace=True)
X_test.dropna(inplace=True)

y_train = y_train[X_train.index]
y_test = y_test[X_test.index]

X_train = pd.get_dummies(X_train)
X_test = pd.get_dummies(X_test)

X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)

"""**Training** **the** **Model**"""

#Random Forest Model

rf_model = RandomForestClassifier(n_estimators=50, random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)

#Feature importances from the trained model
importances = rf_model.feature_importances_

indices = sorted(range(len(importances)), key = lambda i: importances[i],reverse = False)
feature_names = [f"Features {i}" for i in indices]

plt.figure(figsize=(8,14))
plt.barh(range(X_train.shape[1]), importances[indices], align = "center")
plt.yticks(range(X_train.shape[1]), feature_names)
plt.xlabel("Importance")
plt.title("Feature Importance")
plt.show()

"""Model Evaluation"""

#Plot Confusion Matrix
def plot_confusion_matrix(y_true, y_pred, classes, title):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
    plt.title(title)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.gca().invert_yaxis()
    plt.gca().invert_xaxis()
    plt.show()

#Evaluate Random Forest
rf_accuracy = accuracy_score(y_test,rf_pred)
rf_f1 = f1_score(y_test, rf_pred)
rf_precision = precision_score(y_test, rf_pred)
rf_recall = recall_score(y_test,rf_pred)

#Results of Random Forest Model
print('\nRandom Forest Metrics:')
print(f'Accuracy: {rf_accuracy:.4f}')
print(f'F1 Score: {rf_f1:.4f}')
print(f'Precision: {rf_precision:.4f}')
print(f'Recall: {rf_recall:.4f}')

#Confusion Matrix for Random Forest
plot_confusion_matrix(y_test, rf_pred, ['Benign', 'Bot'], 'Random Forest Confusion Matrix')

#Logistic Regression Model
lr_model = LogisticRegression(random_state=42)
lr_model.fit(X_train, y_train)
lr_pred = lr_model.predict(X_test)

#Evaluate Linear Regression
lr_accuracy = accuracy_score(y_test, lr_pred)
lr_f1 = f1_score(y_test, lr_pred)
lr_precision = precision_score(y_test, lr_pred)
lr_recall = recall_score(y_test, lr_pred)

print('\nLogistic Regression Metrics:')
print(f'Accuracy: {lr_accuracy:.4f}')
print(f'F1 Score: {lr_f1:.4f}')
print(f'Precision: {lr_precision:.4f}')
print(f'Recall: {lr_recall:.4f}')

#Confusion Matrix for Logistic Regression
plot_confusion_matrix(y_test, lr_pred, ['Benign', 'Bot'], 'Logistic Regression Confusion Matrix')